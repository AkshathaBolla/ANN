{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkshathaBolla/ANN/blob/main/SmartGrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eli9HFGtZn4T"
      },
      "source": [
        "# Module I: Practice Exercise - 'Smart-Grid AI' (Big Arch Spec)\n",
        "\n",
        "### **Context: The National Energy Grid**\n",
        "You are the Lead Engineer for the National Grid. You have sensor readings from 100 power stations.\n",
        "Your sensors measure:\n",
        "1.  **Temperature (C)**\n",
        "2.  **Wind Speed (km/h)**\n",
        "3.  **Current Load (MW)**\n",
        "\n",
        "You have **two separate goals**:\n",
        "* **Goal A (Stability):** Predict if the grid is **'Unstable' (1)** or **'Stable' (0)**. (Classification)\n",
        "* **Goal B (Demand):** Predict the **Next Hour Demand (MW)**. (Regression)\n",
        "\n",
        "---\n",
        "**INSTRUCTIONS:**\n",
        "This exercise uses **Deeper and Wider Architectures**.\n",
        "Pay attention to the layer dimensions (Input -> Hidden -> Output) to ensure the shapes match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "L1M-XYzwZn4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727e6618-5a11-46e9-9e86-4ef714dd356a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Ready. X: torch.Size([100, 3]), y_stable: torch.Size([100, 1]), y_demand: torch.Size([100, 1])\n"
          ]
        }
      ],
      "source": [
        "# CELL 1: DATA GENERATION (Run this first)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "torch.manual_seed(500)\n",
        "\n",
        "# 100 Power Stations\n",
        "N = 100\n",
        "# Features: Temp (-10 to 40), Wind (0-100), Load (1000-5000)\n",
        "X = torch.rand(N, 3) * torch.tensor([50, 100, 4000]) + torch.tensor([-10, 0, 1000])\n",
        "\n",
        "# Target A: Instability (Classification)\n",
        "# Unstable if (Temp > 35 AND Load > 4500) OR Wind > 90\n",
        "stability_score = (X[:, 0] - 35) + (X[:, 2] - 4500)/100 + (X[:, 1] - 90) + torch.randn(N)*5\n",
        "y_stable = (stability_score > 0).float().view(-1, 1)\n",
        "\n",
        "# Target B: Demand (Regression)\n",
        "# Demand driven by Temp (AC/Heating) and current Load\n",
        "y_demand = (X[:, 2] * 1.1) + (X[:, 0].abs() * 20) + torch.randn(N) * 50\n",
        "y_demand = y_demand.view(-1, 1).float()\n",
        "\n",
        "print(f\"Data Ready. X: {X.shape}, y_stable: {y_stable.shape}, y_demand: {y_demand.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EYwcl6RZn4X"
      },
      "source": [
        "## **Level 1: The Blackout Predictor (Deep Classification)**\n",
        "**Your Task:** Detect Instability.\n",
        "\n",
        "**Blueprint (The 'Funnel' Architecture):**\n",
        "1.  **Input:** 3 Features\n",
        "2.  **Layer 1:** 64 Neurons, `Tanh`\n",
        "3.  **Layer 2:** 32 Neurons, `Tanh`\n",
        "4.  **Layer 3:** 16 Neurons, `Tanh`\n",
        "5.  **Output:** 1 Neuron, `Sigmoid`\n",
        "\n",
        "**Training Specs:**\n",
        "* Loss: `BCELoss`\n",
        "* Optimizer: `SGD` (lr=0.01)\n",
        "* Epochs: 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "m4eAIZpPZn4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80d1ef2-28f9-4bd1-95ee-578931ecaba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:0.9900000095367432\n"
          ]
        }
      ],
      "source": [
        "# LEVEL 1: WRITE YOUR CODE HERE\n",
        "\n",
        "# 1. Define 'GridModel'\n",
        "class GridModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1=nn.Linear(3,64)\n",
        "    self.layer1=nn.Tanh()\n",
        "    self.linear2=nn.Linear(64,32)\n",
        "    self.layer2=nn.Tanh()\n",
        "    self.linear3=nn.Linear(32,16)\n",
        "    self.layer3=nn.Tanh()\n",
        "    self.linear4=nn.Linear(16,1)\n",
        "    self.layer4=nn.Sigmoid()\n",
        "\n",
        "\n",
        "    # TODO: Implement the 4-layer funnel\n",
        "  def forward(self,x):\n",
        "    x=self.linear1(x)\n",
        "    x=self.layer1(x)\n",
        "    x=self.linear2(x)\n",
        "    x=self.layer2(x)\n",
        "    x=self.linear3(x)\n",
        "    x=self.layer3(x)\n",
        "    x=self.linear4(x)\n",
        "    x=self.layer4(x)\n",
        "    return x;\n",
        "\n",
        "model_grid = GridModel()\n",
        "criterion=nn.BCELoss();\n",
        "optimizer=optim.SGD(model_grid.parameters(),lr=0.01)\n",
        "\n",
        "# 2. Optimizer & Loss\n",
        "for epoch in range(200):\n",
        "  optimizer.zero_grad()\n",
        "  pred=model_grid(X);\n",
        "  loss=criterion(pred,y_stable)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "# 3. Training Loop\n",
        "\n",
        "# 4. Accuracy Check\n",
        "with torch.no_grad():\n",
        "  outputs=model_grid(X);\n",
        "  pred=(outputs>=0.5).float()\n",
        "  acc= (pred==y_stable).float().mean()\n",
        "  print(f\"Accuracy:{acc.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Q9F4Df_CZn4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e51dfe-651a-45e2-c7c4-32f6a3c61f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Level 1 Passed: The Funnel Architecture is correct.\n"
          ]
        }
      ],
      "source": [
        "# TEST LEVEL 1\n",
        "try:\n",
        "    # Check Layer Count\n",
        "    layers = [m for m in model_grid.modules() if isinstance(m, nn.Linear)]\n",
        "    assert len(layers) == 4, f\"Blueprint requires 4 Linear layers. Found {len(layers)}\"\n",
        "\n",
        "    # Check Funnel Shapes\n",
        "    assert layers[0].out_features == 64\n",
        "    assert layers[1].out_features == 32\n",
        "    assert layers[2].out_features == 16\n",
        "\n",
        "    print(\"✅ Level 1 Passed: The Funnel Architecture is correct.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Level 1 Fail: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FA7xCa7Zn4Z"
      },
      "source": [
        "## **Level 2: Demand Forecasting (Wide Regression)**\n",
        "**Your Task:** Predict Demand (MW).\n",
        "\n",
        "**Step 2.1: Pipeline**\n",
        "* Split Train(20) / Test(80). `DataLoader` (Batch=10).\n",
        "\n",
        "**Step 2.2: The 'Fat' Model (Overfitting Risk)**\n",
        "* `Linear(3, 256) -> ReLU`\n",
        "* `Linear(256, 256) -> ReLU`\n",
        "* `Linear(256, 1)`\n",
        "\n",
        "**Step 2.3: Diagnosis**\n",
        "* Train for 300 epochs. Confirm Overfitting.\n",
        "\n",
        "**Step 2.4: The Fix (Dropout)**\n",
        "* Rebuild with `nn.Dropout(0.5)` after the first two ReLUs.\n",
        "* Retrain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "i7t1ysTpZn4Z"
      },
      "outputs": [],
      "source": [
        "# LEVEL 2: WRITE YOUR CODE HERE\n",
        "\n",
        "# 1. Data Pipeline\n",
        "X_train,X_test=X[:20],X[20:]\n",
        "y_train,y_test=y_stable[:20],y_stable[20:]\n",
        "\n",
        "train_dataset=TensorDataset(X_train,y_train)\n",
        "test_dataset=TensorDataset(X_test,y_test)\n",
        "\n",
        "train_dataloader=DataLoader(train_dataset,batch_size=10,shuffle=True)\n",
        "test_dataloader=DataLoader(test_dataset,batch_size=10)\n",
        "\n",
        "# 2. Define 'model_fat' (256 width)\n",
        "class ModelFat(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1=nn.Linear(3,256)\n",
        "    self.layer2=nn.ReLU()\n",
        "    self.layer3=nn.Linear(256,256)\n",
        "    self.layer4=nn.ReLU()\n",
        "    self.layer5=nn.Linear(256,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.layer1(x)\n",
        "    x=self.layer2(x)\n",
        "    x=self.layer3(x)\n",
        "    x=self.layer4(x)\n",
        "    x=self.layer5(x)\n",
        "    return x\n",
        "model_fat=ModelFat()\n",
        "# 3. Train Loop\n",
        "optimizer=optim.SGD(model_fat.parameters(),lr=0.01)\n",
        "criterion=nn.MSELoss()\n",
        "for epoch in range(300):\n",
        "  model_fat.train()\n",
        "  for inputs,target in train_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    pred=model_fat(inputs)\n",
        "    loss=criterion(pred,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        " # 4. Define 'model_smart' (With Dropout 0.5)\n",
        "class ModelSmart(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1=nn.Linear(3,256)\n",
        "    self.layer2=nn.ReLU()\n",
        "    self.droput1=nn.Dropout(0.5)\n",
        "    self.layer3=nn.Linear(256,256)\n",
        "    self.layer4=nn.ReLU()\n",
        "    self.dropout2=nn.Dropout(0.5)\n",
        "    self.layer5=nn.Linear(256,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.layer1(x)\n",
        "    x=self.layer2(x)\n",
        "    x=self.droput1(x)\n",
        "    x=self.layer3(x)\n",
        "    x=self.layer4(x)\n",
        "    x=self.dropout2(x)\n",
        "    x=self.layer5(x)\n",
        "    return x\n",
        "model_smart=ModelSmart()\n",
        "optimizer=optim.SGD(model_smart.parameters(),lr=0.01)\n",
        "criterion=nn.MSELoss()\n",
        "for epoch in range(300):\n",
        "  model_smart.train()\n",
        "  for inputs,target in train_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    target=target.view(-1,1)\n",
        "    pred=model_smart(inputs)\n",
        "    loss=criterion(pred,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Mu04kw_mZn4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf2d403-86c7-4b16-ce25-cb90bd5a5b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Level 2 Passed: Wide Architecture built correctly.\n"
          ]
        }
      ],
      "source": [
        "# TEST LEVEL 2\n",
        "try:\n",
        "    # Check Width\n",
        "    l1 = list(model_smart.modules())[1]\n",
        "    if isinstance(l1, nn.Sequential): l1 = l1[0]\n",
        "    assert l1.out_features == 256, f\"Hidden layer must be 256 wide. Found {l1.out_features}\"\n",
        "\n",
        "    # Check Dropout\n",
        "    drop = [m for m in model_smart.modules() if isinstance(m, nn.Dropout)]\n",
        "    assert len(drop) >= 2, \"Missing dropout layers\"\n",
        "    assert drop[0].p == 0.5, \"Dropout rate must be 0.5\"\n",
        "\n",
        "    print(\"✅ Level 2 Passed: Wide Architecture built correctly.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Level 2 Fail: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hfQ687XZn4Z"
      },
      "source": [
        "## **Level 3: The Architect (Manual MAE)**\n",
        "\n",
        "**Part 3.1: Manual MAE (Mean Absolute Error)**\n",
        "Implement `my_custom_mae`.\n",
        "$$ Loss = Mean( |y_{pred} - y_{true}| ) $$\n",
        "*Hint: Use `torch.abs()`.*\n",
        "\n",
        "**Part 3.2: The Tournament**\n",
        "Compare these 3 configs on **Demand Prediction**:\n",
        "\n",
        "1.  **\"Standard\"**: `Linear(3, 64) -> ReLU -> Linear(64, 1)` (Loss: `MSELoss`)\n",
        "2.  **\"Leaky\"**: `Linear(3, 64) -> LeakyReLU(0.1) -> Linear(64, 1)` (Loss: `L1Loss`)\n",
        "3.  **\"Mobile\"**: `Linear(3, 64) -> Hardswish -> Linear(64, 1)` (Loss: **YOUR** `my_custom_mae`)\n",
        "\n",
        "**Note:** `Hardswish` is a memory-efficient activation used in MobileNetV3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1oLypwHPZn4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9c67fd7-1490-4ce9-9a1a-f48e7f9b15e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name       | Test Loss \n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "# LEVEL 3.1: MANUAL MAE\n",
        "def my_custom_mae(pred, target):\n",
        "    # TODO: Implement Mean Absolute Error\n",
        "    abs_error=torch.abs(pred-target)\n",
        "    return torch.mean(abs_error)\n",
        "\n",
        "# LEVEL 3.2: TOURNAMENT\n",
        "experiments = [\n",
        "    {\"name\": \"Standard\", \"act\": nn.ReLU(), \"loss\": nn.MSELoss()}, # ReLU, MSE\n",
        "    {\"name\": \"Leaky\",    \"act\": nn.LeakyReLU(), \"loss\": nn.L1Loss()}, # LeakyReLU(0.1), L1\n",
        "    {\"name\": \"Mobile\",   \"act\": nn.Hardswish(), \"loss\": my_custom_mae}  # Hardswish, Custom MAE\n",
        "]\n",
        "\n",
        "print(f\"{'Name':<10} | {'Test Loss':<10}\")\n",
        "print(\"-\"*25)\n",
        "\n",
        "# Loop..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VEQ3ZPR1Zn4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312e9270-f8e3-4d78-977e-484c0f437466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Level 3 Passed: Manual MAE and Configs valid.\n"
          ]
        }
      ],
      "source": [
        "# TEST LEVEL 3\n",
        "try:\n",
        "    # Test Math\n",
        "    p = torch.tensor([-2.0]); t = torch.tensor([2.0])\n",
        "    assert my_custom_mae(p, t).item() == 4.0, \"Math Fail: |-2 - 2| should be 4\"\n",
        "\n",
        "    # Check Configs\n",
        "    assert isinstance(experiments[2]['act'], nn.Hardswish), \"Exp 3 Act must be Hardswish\"\n",
        "    assert not isinstance(experiments[2]['loss'], type), \"Exp 3 Loss must be custom function\"\n",
        "\n",
        "    print(\"✅ Level 3 Passed: Manual MAE and Configs valid.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Level 3 Fail: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yGQEjGxZn4a"
      },
      "source": [
        "## **Level 4: The Mechanic (Manual Optimization)**\n",
        "**Your Task:** The `optim` library is deleted. Train a simple Linear Regression model manually.\n",
        "\n",
        "1.  Create a single layer `nn.Linear(1, 1)`.\n",
        "2.  Write a loop that updates weights using: `w = w - lr * gradient`.\n",
        "3.  **Important:** You must use `with torch.no_grad():` for the update step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KJa9mElyZn4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc343b6-61ba-4a3e-da4a-1578912e13e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizers deleted. You are on your own.\n"
          ]
        }
      ],
      "source": [
        "# LEVEL 4: THE PURGE (Run this to delete optimizers)\n",
        "import torch.optim as optim\n",
        "import gc\n",
        "for var in list(locals().keys()):\n",
        "    if 'opt' in var or 'optimizer' in var:\n",
        "        del locals()[var]\n",
        "gc.collect()\n",
        "print(\"Optimizers deleted. You are on your own.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "O_SPOFGwZn4b"
      },
      "outputs": [],
      "source": [
        "# LEVEL 4: WRITE YOUR CODE HERE\n",
        "\n",
        "# 1. Setup Data\n",
        "X_simple = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "y_simple = torch.tensor([[3.0], [5.0], [7.0], [9.0]]) # Target: y = 2x + 1\n",
        "\n",
        "# 2. Define Model\n",
        "model_manual = nn.Linear(1,1)\n",
        "lr=0.01\n",
        "criterion=nn.MSELoss()\n",
        "for epoch in range(3000):\n",
        "  preds=model_manual(X_simple)\n",
        "  loss=criterion(preds,y_simple)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "        model_manual.weight-=lr*model_manual.weight.grad\n",
        "\n",
        "# 3. Manual Loop\n",
        "\n",
        "    # Forward, Loss, Backward\n",
        "    # Update: param -= lr * param.grad\n",
        "    # Zero grad\n",
        "  model_manual.weight.grad.zero_()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "_QuDQgVoZn4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0c7fd3-1deb-43f7-accc-a71ecf46b34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Level 4 Passed: Manual Optimization successful!\n"
          ]
        }
      ],
      "source": [
        "# TEST LEVEL 4\n",
        "try:\n",
        "    w = model_manual.weight.item()\n",
        "    b = model_manual.bias.item()\n",
        "    assert abs(w - 2.0) < 0.2, f\"Convergence Fail: Weight is {w:.2f}, expected ~2.0\"\n",
        "    print(\"✅ Level 4 Passed: Manual Optimization successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Level 4 Fail: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sScq1JmX8Qe2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}